<!DOCTYPE html>
<html>
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4NF4X02K2T"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4NF4X02K2T');
</script>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>FFHQ-Makeup</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yangxingchao.github.io/publications/" target="_blank">Xingchao Yang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://sh1027.github.io/en" target="_blank">Shiori Ueda</a><sup>2</sup>
              <span class="author-block">
                <a href="https://sky24h.github.io/" target="_blank">Yuantian Huang</a><sup>1</sup>
              <span class="author-block">
                <a href="https://yangxingchao.github.io/FFHQ-Makeup-page/" target="_blank">Tomoya Akiyama</a><sup>1</sup>
              <span class="author-block">
                <a href="https://taketomitakafumi.sakura.ne.jp/web/en/" target="_blank">Takafumi Taketomi</a><sup>1</sup>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup> CyberAgent, AI Lab </span><br>
                    <span class="author-block"><sup>2</sup> Keio University </span>
                    <span class="eql-cntrb"><small><br>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/2503.17197.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/EG2023_MakeupExtraction_Supplementary.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2508.03241" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YangXingchao/FFHQ-Makeup" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(Coming Soon)</span>
                  </a>
                </span>

                <!-- Dataset link -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/cyberagent/FFHQ-Makeup" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-folder-open"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpg" alt="Banner image" height="100%">
      <h2 class="subtitle has-text-centered">
        Examples from our FFHQ-Makeup dataset, where each identity is paired with a bare image and multiple makeup-applied images, demonstrating identity and expression consistency under diverse makeup styles.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->



<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/eg_makeup_2023.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered"><br>
        3D Avatar is widely used in movies and advertisements, with facial makeup being a crucial aspect of creating these lifelike digital characters. However, the process of editing makeup on a 3D face or using specialized equipment can be time-consuming. To obtain facial makeup for 3D characters, we propose a method to extract makeup from a single face image in a UV format that can be used for 3D face models. We unwarp the input image to UV texture so that it can be applied to a 3D face model. Then, we decompose the UV texture to bare skin, makeup, and lighting effects.
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Paired bare-makeup facial images are essential for a wide range of beauty-related tasks, such as virtual try-on, facial privacy protection, and facial aesthetics analysis. However, collecting high-quality paired makeup datasets remains a significant challenge. Real-world data acquisition is constrained by the difficulty of collecting large-scale paired images, while existing synthetic approaches often suffer from limited realism or inconsistencies between bare and makeup images.
            Current synthetic methods typically fall into two categories: warping-based transformations, which often distort facial geometry and compromise the precision of makeup; and text-to-image generation, which tends to alter facial identity and expression, undermining consistency.
            <br>
            In this work, we present <strong>FFHQ-Makeup</strong>, a high-quality synthetic makeup dataset that pairs each identity with multiple makeup styles while preserving facial consistency in both identity and expression. Built upon the diverse FFHQ dataset, our pipeline transfers real-world makeup styles from existing datasets onto 18K identities by introducing an improved makeup transfer method that disentangles identity and makeup. Each identity is paired with 5 different makeup styles, resulting in a total of 90K high-quality bare–makeup image pairs.
            <br>
            To the best of our knowledge, this is the first work that focuses specifically on constructing makeup dataset.
            <br>
            We hope that FFHQ-Makeup fills the gap of lacking high-quality bare–makeup paired datasets and serves as a valuable resource for future research in beauty-related tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Dataset summary section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-nine-tenths">
        <h2 class="title is-3">Summary of existing makeup datasets</h2>
        <div class="content has-text-justified">
          <div class="has-text-centered">
            <p class="has-text-centered" style="margin-top: 10px; font-size: 0.9em;">
              Real-world data collection is hindered by logistical constraints, limited resources, and privacy concerns.
              <br>
              synthetic approaches often suffer from limited realism or inconsistencies between bare and makeup images.
            </p>
            <img src="static/images/result_dataset_evaluation.jpg" alt="dataseet compare" width="70%">
            <img src="static/images/table.jpg" alt="Datasets summary" width="100%">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Dataset summary section -->

<!-- FFHQ-Makeup section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-nine-tenths">
        <h2 class="title is-3">FFHQ-Makeup</h2>
        <div class="content has-text-centered">
          <img src="static/images/result_ffhq_makeup.jpg" alt="Method Overview" width="100%">
          <p class="has-text-justified">
            Our FFHQ-Makeup dataset inherits the diversity of FFHQ. As shown, it includes multiple bare-makeup pairs examples across different ethnicities, ages, genders, expressions, and cases with occlusions or shadows.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End FFHQ-Makeup section -->

<!-- Makeup Transfer for Dataset Generation section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-nine-tenths">
        <h2 class="title is-3">Makeup Transfer for Dataset Generation</h2>
        <div class="content has-text-centered">
          <img src="static/images/result_makeup_transfer.jpg" alt="Method Overview" width="100%">
          <p class="has-text-justified">
            Comparison of makeup transfer methods for dataset generation. Our method best preserves the target identity and expression while producing visually plausible makeup. In contrast, other methods often introduce artifacts or alter key facial attributes such as identity and expression.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Makeup Transfer for Dataset Generation section -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{yang_2025_ffhq_makeup,
        title={FFHQ-Makeup: Paired Synthetic Makeup Dataset with Facial Consistency Across Multiple Styles}, 
        author={Xingchao Yang and Shiori Ueda and Yuantian Huang and Tomoya Akiyama and Takafumi Taketomi},
        booktitle={arXiv},
        year={2025},
  }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
